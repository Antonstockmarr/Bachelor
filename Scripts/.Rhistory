dxdt <- c(dSH,dIH,dRH,dSM,dIM)
list(dxdt)
})
}
## Parameter vector
p <- c(nuH=nuH,NH=NH,muH=muH,gammaH=gammaH,deltaH=deltaH,nuM=nuM,NM=NM,muM=muM,betaH=betaH,betaM=betaM)
## Initial conditions
x0 <- c(SH=1e2,IH=0,RH=0,SM=1e5,IM=0)
require(deSolve)
## Time points where we want the solution
times <- seq(0,10,0.01)
## Solve and plot
sol <- data.frame(ode(x0,times,model,p))
(plot(sol))
## Code to solve an ODE model of a Human/Mosquito vector-borne disease
## Parameters
nuH <- 0.01   # Per year
NH <- 1000    # # Humans
muH <- 0.01   # Per year
NM <- 1e6     # # Mosquitos
nuM <- 1      # Per year
muM <- 1      # Per year
gammaH <- 52  # Per year
deltaH <- 1   # Per year
betaH <- 3e-4 # ?
betaM <- 3e-4 # ?
## Right hand side of the differential equation
model <- function(t,x,p)
{
with(as.list(c(x,p)),{
dSH <- nuH*NH-muH*SH-betaH*SH*IM + deltaH*RH
dIH <- betaH*SH*IM - muH*IH - gammaH*IH
dRH <- gammaH*IH - muH*RH - deltaH*RH
dSM <- nuM*NM - muM*SM - betaM*SM*IH
dIM <- betaM*SM*IH - muM*IM
dxdt <- c(dSH,dIH,dRH,dSM,dIM)
list(dxdt)
})
}
## Parameter vector
p <- c(nuH=nuH,NH=NH,muH=muH,gammaH=gammaH,deltaH=deltaH,nuM=nuM,NM=NM,muM=muM,betaH=betaH,betaM=betaM)
## Initial conditions
x0 <- c(SH=1e2,IH=0,RH=0,SM=1e5,IM=0)
require(deSolve)
## Time points where we want the solution
times <- seq(0,1*50,0.01)
## Solve and plot
sol <- data.frame(ode(x0,times,model,p))
(plot(sol))
## Solve and plot
sol <- data.frame(ode(x0,times,model,p))
(plot(sol))
source('~/Downloads/vektor.R', echo=TRUE)
plot(X$SH, type = "l", col= "blue", ylim = c(100,1e6), xlim = c(0,10000), main = "Smittede mennesker i den endemiske tilstand")
plot(X$SH, type = "l", col= "blue", ylim = c(100,1e6), xlim = c(0,10000), main = "Smittede mennesker i den endemiske tilstand")
lines(sol$SH, type = "l", col = "red")
knitr::opts_chunk$set(echo = TRUE)
A <- matrix(c(0,0,.543,6.48,10.61,11.2, .112,-.49,.082,.111,0,0,
.001 ,.27,.36,.222,0,0,
0,.0015,.237,.487,.014,.2,
0,0,0,0.182,.486,.65),5,6,byrow = TRUE)
B <- matrix(c(0,0,.874,7.45,16.45, .234,.56,.134,.111,0,
.01 ,.34,.45,.245,0,
0,.012,.165,.573,.125,
0,0,0,0.065,.654),5,5,byrow = TRUE)
(eig.B <- Re(eigen(B)$values[1]))
(ew.B <- Re(eigen(B)$vectors[,1]))
ev.B <- Re(eigen(t(B))$vectors[,1])
e.B <- matrix(NA, ncol = 5, nrow = 5)
dim.B <- dim(B)[1]
for (i in 1:dim.B) {
for (j in 1:dim.B) {
e.B[i,j] <- ev.B[i] * ew.B[j] / ev.B%*%ew.B * B[i,j] / eigen(B)$values[1]
}
}
(e.B <- matrix(as.numeric(e.B), ncol = 5, byrow = FALSE))
## Code to solve an ODE model of a Human/Mosquito vector-borne disease
## Parameters
nuH <- 0.01   # Per year
NH <- 1000    # # Humans
muH <- 0.01   # Per year
NM <- 1e6     # # Mosquitos
nuM <- 1      # Per year
muM <- 1      # Per year
gammaH <- 52  # Per year
deltaH <- 1   # Per year
betaH <- 3e-4 # ?
betaM <- 3e-4 # ?
## Right hand side of the differential equation
model <- function(t,x,p)
{
with(as.list(c(x,p)),{
dSH <- nuH*NH-muH*SH-betaH*SH*IM + deltaH*RH
dIH <- betaH*SH*IM - muH*IH - gammaH*IH
dRH <- gammaH*IH - muH*RH - deltaH*RH
dSM <- nuM*NM - muM*SM - betaM*SM*IH
dIM <- betaM*SM*IH - muM*IM
dxdt <- c(dSH,dIH,dRH,dSM,dIM)
list(dxdt)
})
}
## Parameter vector
p <- c(nuH=nuH,NH=NH,muH=muH,gammaH=gammaH,deltaH=deltaH,nuM=nuM,NM=NM,muM=muM,betaH=betaH,betaM=betaM)
## Initial conditions
x0 <- c(SH=1e2,IH=0,RH=0,SM=1e5,IM=0)
require(deSolve)
## Time points where we want the solution
times <- seq(0,1*3000,0.01)
## Solve and plot
sol <- ode(x0,times,model,p)
plot(sol)
sol <- ode(x0,times,model,p)
plot(sol)
plot(sol)
## Code to simulate a stochastic Human/Mosquito vector-borne disease
## Parameters
nuH <- 0.01   # Per year
NH <- 1000    # # Humans
muH <- 0.01   # Per year
NM <- 1e6     # # Mosquitos
nuM <- 1      # Per year
muM <- 1      # Per year
gammaH <- 52  # Per year
deltaH <- 1   # Per year
betaH <- 3e-4 # ?
betaM <- 3e-4 # ?
## Time step control (DISREGARD WHY THIS IS DONE THIS WAY)
dt <- 1/max(c(betaH*NM*nuM/muM,betaM*NH*nuH/muH),nuH,muH,gammaH,deltaH,nuM,muM)
## Time step the system dt
timestep <- function(x)
{ with(as.list(x),{
## All transitions EXCEPT deaths
HumanBirths <- rbinom(n=1,NH,nuH*dt)
HumanInfections <- rbinom(n=1,SH,betaH*IM*dt)
HumanRecoveries <- rbinom(n=1,IH,gammaH*dt)
HumanImmunityLosses <- rbinom(n=1,RH,deltaH*dt)
SH <- SH + HumanBirths - HumanInfections + HumanImmunityLosses
IH <- IH + HumanInfections - HumanRecoveries
RH <- RH + HumanRecoveries - HumanImmunityLosses
MosquitoBirths <- rbinom(n=1,NM,nuM*dt)
MosquitoInfections <- rbinom(n=1,SM,betaM*IH*dt)
SM <- SM + MosquitoBirths - MosquitoInfections
IM <- IM + MosquitoInfections
## Deaths
SH <- SH - rbinom(n=1,SH,muH*dt)
IH <- IH - rbinom(n=1,IH,muH*dt)
RH <- RH - rbinom(n=1,RH,muH*dt)
SM <- SM - rbinom(n=1,SM,muM*dt)
IM <- IM - rbinom(n=1,IM,muM*dt)
return(c(SH,IH,RH,SM,IM))
}) }
## Simulate the system for a number of time steps
simulate <- function(x0,N)
{
X <- array(NA,c(5,N))
rownames(X) <- names(x0)
X[,1] <- x0
for(i in 2:N)
{
X[,i] <- timestep(X[,i-1])
}
return(as.data.frame(t(X)))
}
## Set initial condition
x0 <- c(SH=1e2,IH=0,RH=0,SM=1e5,IM=0)
## Simulate
X <- simulate(x0,10000)
## Plot one of the variables
plot(X$SM, type = "l", col = "blue", ylim = c(1e5,10e5), main = "Smittede myg i den endemiske tilstand")
lines(sol$SM, type = "l", col= "red")
plot(X$SM, type = "l", col = "blue", ylim = c(1e5,10e5), main = "Smittede myg i den endemiske tilstand")
lines(sol$SM, type = "l", col= "red")
lines(sol$SM, type = "l", col= "red")
plot(X$SM, type = "l", col = "blue", ylim = c(1e5,10e5), main = "Smittede myg i den endemiske tilstand")
lines(sol$SM, type = "l", col= "red")
## Time points where we want the solution
times <- seq(0,1*50,0.01)
## Solve and plot
sol <- ode(x0,times,model,p)
(plot(sol))
plot(X$SM, type = "l", col = "blue", ylim = c(1e5,10e5), main = "Smittede myg i den endemiske tilstand")
lines(sol$SM, type = "l", col= "red")
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
par(mar=c(3,3,2,1), mgp=c(2,0.7,0))
source("data.R")
for (i in 1:n) {
print(paste('Modeling house ',i))
model.tmp <- model.data[[i]]
model.tmp <- model.tmp[model.tmp$Temperature <= 12,]
lm.simple[[i]] <- lm(Consumption ~ Temperature, data = model.tmp)
print(summary(lm.simple[[i]]))
# Checking model assumptions
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lm.simple[[i]])
title(paste("Daily consumption for house ", i, "using simple lm"), outer=TRUE, adj = 0.5, line = -1.25)
# Testing for normality
s.test[[i]] <- shapiro.test(lm.simple[[i]]$residuals)
print(s.test[[i]]$p.value)
sign.test[[i]] <- binom.test(x = sum(sign(lm.simple[[i]]$residuals) == 1), n = length(lm.simple[[i]]$residuals))
print(sign.test[[i]]$p.value)
# 95% confidence interval
}
# Initializing
s.test <- vector(mode = "list", length = n)
sign.test <- vector(mode = "list", length = n)
lm.simple <- vector(mode = "list", length = n)
model.data <- weatherCons
for (i in 1:n) {
print(paste('Modeling house ',i))
model.tmp <- model.data[[i]]
model.tmp <- model.tmp[model.tmp$Temperature <= 12,]
lm.simple[[i]] <- lm(Consumption ~ Temperature, data = model.tmp)
print(summary(lm.simple[[i]]))
# Checking model assumptions
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lm.simple[[i]])
title(paste("Daily consumption for house ", i, "using simple lm"), outer=TRUE, adj = 0.5, line = -1.25)
# Testing for normality
s.test[[i]] <- shapiro.test(lm.simple[[i]]$residuals)
print(s.test[[i]]$p.value)
sign.test[[i]] <- binom.test(x = sum(sign(lm.simple[[i]]$residuals) == 1), n = length(lm.simple[[i]]$residuals))
print(sign.test[[i]]$p.value)
# 95% confidence interval
}
source('~/Dropbox/DTU/6. semester/Bachelorprojekt F19/Bachelor/scripts/MultipleRegression.R', echo=TRUE)
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lmMultipleNoP[[18]])
title(paste("Daily consumption for house ", i), outer=TRUE, adj = 0.5, line = -1.25)
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lmMultipleNoP[[18]])
title(paste("Daily consumption for house ", 18), outer=TRUE, adj = 0.5, line = -1.25)
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lmMultipleNoP[[55]])
title(paste("Daily consumption for house ", 55), outer=TRUE, adj = 0.5, line = -1.25)
par(mfrow = c(2,2), mar = c(3,3,3,1) + 0.1)
plot(lmMultipleNoP[[68]])
title(paste("Daily consumption for house ", 68), outer=TRUE, adj = 0.5, line = -1.25)
View(weather)
source("data.R")
library("forecast")
library("forecast")
library("marima")
install.packages("forecast")
install.packages("marima")
!
for(i in 1:n){
nas<-which(!is.na(data[[i]]$Flow))
tmp.dat<-data[[i]][nas[1]:tail(nas,1),]
nas<-which(is.na(tmp.dat$Flow))
m<-dim(tmp.dat)[2]
for(j in nas){
tmp.dat[j,2:m]<-(data[[i]][j-1,2:m]+data[[i]][j+1,2:m])/2
}
data[[i]]<-tmp.dat
}
nas
source("data.R")
for(i in 1:n){
nas<-which(!is.na(data[[i]]$Flow))
tmp.dat<-data[[i]][nas[1]:tail(nas,1),]
nas<-which(is.na(tmp.dat$Flow))
m<-dim(tmp.dat)[2]
for(j in nas){
tmp.dat[j,2:m]<-(data[[i]][j-1,2:m]+data[[i]][j+1,2:m])/2
}
data[[i]]<-tmp.dat
}
nas
source("data.R")
library("forecast")
library("marima")
for(i in 1:n){
nas<-which(!is.na(data[[i]]$Flow))
tmp.dat<-data[[i]][nas[1]:tail(nas,1),]
nas<-which(is.na(tmp.dat$Flow))
m<-dim(tmp.dat)[2]
for(j in nas){
tmp.dat[j,2:m]<-(data[[i]][j-1,2:m]+data[[i]][j+1,2:m])/2
}
data[[i]]<-tmp.dat
}
nas
tmp.dat
m
# Initializing workspace and directory.
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
par(mar=c(3,3,2,1), mgp=c(2,0.7,0))
# Sources and packages
source("DataChecking.R")
source("Polarize.R")
source("Sun.R")
library(xts)
library(solaR)
# Watts colorscheme
Wcol=c(1,rgb(132,202,41,maxColorValue = 255),rgb(231,176,59,maxColorValue = 255),rgb(229,56,50,maxColorValue = 255))
# Loading all data
data.path = "../Consumption data/"
file.names <- dir(data.path, pattern =".csv")
n <- length(file.names)
Datalengths = rep(1,nrow=n)
data <- vector(mode="list", length = n)
day.data <- vector(mode="list", length = n)
data.key <- rep("",n)
# Saving a specific saturday and sunday for the attribute "Weekend"
Weekend=weekdays(as.POSIXlt(c(as.Date('2019-01-26'),as.Date('2019-01-27')),format = "%Y-%m-%d", tz = "GMT"),abbreviate = TRUE)
sat<-substring(Weekend[1],1:2,1:2)
sun<-substring(Weekend[2],1:2,1:2)
# Loading a single table to initialize dates
dt.tmp <- read.table(paste(data.path,file.names[1], sep = ""), sep=";", stringsAsFactors=FALSE, header = TRUE, dec=',')
names(dt.tmp)[1] = 'StartDateTime'
StartDays <- strptime(dt.tmp$EndDateTime[1:n], format = "%d-%m-%Y %H:%M:%S", tz = "GMT")
EndDays <- strptime(dt.tmp$EndDateTime[1:n], format = "%d-%m-%Y %H:%M:%S", tz = "GMT")
# saving the number of data-set is used.
k <- 0;
# Big for-loop for loading data.
for(i in 1:n){
dt.tmp <- read.table(paste(data.path,file.names[i], sep = ""), sep=";", stringsAsFactors=FALSE, header = TRUE, dec=',')
# removing weird NA attribute.
dt.tmp$X <- NULL
# Using "EndTime" as "ObsTime" and dropping "StartTime"
dt.tmp <- dt.tmp[,-1]
names(dt.tmp)[1]="ObsTime"
dt.tmp$ObsTime <- strptime(dt.tmp$ObsTime, format = "%d-%m-%Y %H:%M:%S", tz = "GMT")
# Add logical vairable for weekends
tmp.wd <- as.Date(dt.tmp$ObsTime,tz="GMT")
tmp.wd <-weekdays(tmp.wd,abbreviate = TRUE)
dt.tmp$Weekend <- grepl(intersect(sat,sun),tmp.wd)
#Make a copy before adding NA's.
dt.tmp.noNA<- dt.tmp
# Fill missing null values.
tmp.xts <- xts(dt.tmp[,-1], order.by=dt.tmp[,1])
t1<-rev(seq(from=(tail(dt.tmp$ObsTime,n=1)-hour(tail(dt.tmp$ObsTime,n=1))*60*60), to=(dt.tmp$ObsTime[1]+(23-hour(dt.tmp$ObsTime[1]))*60*60), by="hour"))
d1 <- xts(rep(1,length(t1)), order.by=t1)
x <- merge(d1,tmp.xts,all=TRUE)
tmp.df <- data.frame(ObsTime=index(x),coredata(x[,-1]))
dt.tmp <- tmp.df[dim(tmp.df)[1]:1,]
# Setting parameters for data checking
par = c('min_obs'=1000, 'miss_fraction'=1/20)
# If the data check is ok, store that data set
if (DataChecking(dt.tmp,par)==TRUE)
{
# Keep track of the amount stored datasets.
k=k+1
data[[k]] <- dt.tmp
#Making daily data
tmp.dat <- dt.tmp.noNA
tmp.dat$ObsTime <- as.Date(tmp.dat$ObsTime,tz="GMT")
tmp.dat$Obs <- rep(1,length(tmp.dat$ObsTime))
tmp.d1 <-aggregate(x=tmp.dat[,-1],by= data.frame(Date = tmp.dat[,1]),FUN = mean)
tmp.d2 <-aggregate(x=tmp.dat[,9],by= data.frame(Date = tmp.dat[,1]),FUN = sum)
tmp.d1[,2:4]<-tmp.d1[,2:4]*24 # Sum instead of mean (when there is 24 points) otherwise weight to 24 points
tmp.dat <-data.frame(tmp.d1[,-9],Obs=tmp.d2[,2])
# Fill missing null values.
tmp.xts <- xts(tmp.dat[,-1], order.by=tmp.dat[,1])
t1<-rev(seq(from=tmp.dat$Date[1], to=tail(tmp.dat$Date,n=1), by="day"))
d1 <- xts(rep(1,length(t1)), order.by=t1)
x <- merge(d1,tmp.xts,all=TRUE)
tmp.df <- data.frame(Date=index(x),coredata(x[,-1]))
tmp.dat <- tmp.df[dim(tmp.df)[1]:1,]
day.data[[k]] <-tmp.dat
data.key[k]<-substr(file.names[i],1,36)
}
}
#removing unused allocated spaces.
if (k<n){
data<-data[-(k+1:n)]
day.data<-day.data[-(k+1:n)]
data.key<-data.key[-(k+1:n)]
Datalengths<-Datalengths[-(k+1:n)]
}
# k is new n
n <- k
#Removing Feb data to get rid of NA
jan1<-day.data[[1]]$Date[1]
for(i in 1:n){
while(day.data[[i]]$Date[1]>jan1){
day.data[[i]]<-day.data[[i]][-1,]
}
# Saving the amount of observations in each table (with NA's).
Datalengths[i]=length(day.data[[i]]$Date)
# Setting start and end times for each table.
EndDays[i]= day.data[[i]]$Date[1]
StartDays[i]=day.data[[i]]$Date[length(day.data[[i]]$Date)]
}
#Removing Feb data from hour data
jan1<-data[[1]]$ObsTime[1]
for(i in 1:n){
while(data[[i]]$ObsTime[1]>jan1){
data[[i]]<-data[[i]][-1,]
}
}
# Loading BBR data, and sorting it with the key.
tmp.df<-data.frame(Key=data.key)
BBR.tmp <- read.table('../BBRdata.csv', sep=";", stringsAsFactors=FALSE, header = TRUE, dec=',')
BBR <- merge(tmp.df,BBR.tmp)
# HouseType into continous variable
BBR$HouseType <- as.factor(BBR$HouseType)
# Reading weather data
weather <- read.table('../WeatherData_01-01-2018_02-06-2019.csv', sep=";", stringsAsFactors=FALSE, header = TRUE, dec=',')
names(weather)[1]="ObsTime"
weather$ObsTime = strptime(weather$ObsTime,format='%d-%m-%Y %H:%M:%S',tz = 'GMT')
weather$IsHistoricalEstimated=weather$IsHistoricalEstimated=="True"
weather$X <- NULL
weather$Radiation <- Sun(weather$ObsTime[1],tail(weather$ObsTime,n=1))
# Removing the attribute UltraVioletIndex
weather$UltraVioletIndex <- NULL
# Sorting dates
sStartDays <- StartDays[order(StartDays)]
sEndDays <- EndDays[order(EndDays)]
weatherStart = weather$ObsTime[1]
weatherEnd = weather$ObsTime[length(weather$ObsTime[weather$IsHistoricalEstimated==FALSE])]
weather <- weather[dim(weather)[1]:1,]
# Making temporary weather data in order to merge it with the house data
tmp <- weather[(weather$ObsTime <= EndDays[42]),]
tmp <- tmp[tmp$ObsTime >= StartDays[42],]
#Making daily weather data
tmp.dat <- weather
tmp.dat$ObsTime <- as.Date(tmp.dat$ObsTime,tz="GMT")
tmp.dat$Obs <- rep(1,length(tmp.dat$ObsTime))
# Making tmp.d1 the mean of every attribute for each day except for obs and sunHour.
tmp.d1 <-aggregate(x=tmp.dat[,-1],by= data.frame(Date = tmp.dat[,1]),FUN = mean)
# Making tmp.d2 the sum of obs and sunhour
tmp.d2 <-aggregate(x=tmp.dat[,c(5,14)],by= data.frame(Date = tmp.dat[,1]),FUN = sum)
# Combining the two dataframes to a single one
tmp.dat <-data.frame(tmp.d1[,-c(5,14)],SunHour = tmp.d2[,2],Obs=tmp.d2[,3])
# Combining Radiation with sunhour
tmp.dat$Radiation <- tmp.dat$SunHour*tmp.dat$Radiation
day.weather <-tmp.dat
# Switching the rows, such that the newest days are first
day.weather <- day.weather[dim(day.weather)[1]:1,]
# WindSpeed and WindDirection transformed to a daily average.
tmp.rekt <- matrix(data=rep(0,length(weather$ObsTime)*2),ncol=2)
tmp.rekt[,1] = sin(weather$WindDirection/180*pi)*weather$WindSpeed
tmp.rekt[,2] = cos(weather$WindDirection/180*pi)*weather$WindSpeed
tmp.coord <- aggregate(x=tmp.rekt,by=data.frame(Date = as.Date(weather$ObsTime,tz="GMT")),FUN = mean)
tmp.coord <- tmp.coord[dim(tmp.coord)[1]:1,]
tmp.polar <- matrix(rep(0,length(tmp.coord[,1])*2),ncol=2)
for (i in 1:length(tmp.coord[,1]))
{
tmp.polar[i,] <- Polarize(tmp.coord[i,2],tmp.coord[i,3])
}
day.weather$WindSpeed <- tmp.polar[,1]
day.weather$WindDirection <- tmp.polar[,2]
head(weather$ObsTime)
head(tmp.coord)
# Making temporary weather data in order to merge it with the house data
day.tmp <- day.weather[(day.weather$Date <= as.Date(EndDays[42],tz="GMT")),]
day.tmp <- day.tmp[day.tmp$Date >= as.Date(StartDays[42],tz="GMT"),]
# Making average daily data:
day.avg <- day.data[[match(max(Datalengths),Datalengths)]]
m=dim(day.avg)[2]
for(j in 2:m){
day.avg[,j] <- rep(0,length(day.avg[,1]))
weightavg<-rep(0,length(day.avg[,1]))
for (i in 1:n){
tmp.index<-1+difftime(as.Date(max(EndDays),tz="GMT"),as.Date(EndDays[i],tz="GMT"), units ="day"):difftime(as.Date(max(EndDays),tz="GMT"),as.Date(StartDays[i],tz="GMT"), units ="day")
tmp.data=day.data[[i]][,j]
tmp.index<- tmp.index[!is.na(tmp.data)]
day.avg[tmp.index,j] <- day.avg[tmp.index,j] + tmp.data
weightavg[tmp.index] <- weightavg[tmp.index] + rep(1,length(tmp.data)) - is.na(day.data[[i]]$Flow)
}
day.avg[,j] <- day.avg[,j]/weightavg
}
# Adding consumption attribute to daily avg. house data
day.avg$Consumption <- day.avg$Volume*day.avg$CoolingDegree
# Making a dataset with selected attributes for each house
weatherCons <- vector(mode="list", length = n)
for (i in 1:n)
{
day.tmp <- day.weather[(day.weather$Date <= as.Date(EndDays[i],tz="GMT")),]
day.tmp <- day.tmp[day.tmp$Date >= as.Date(StartDays[i],tz="GMT"),]
day.tmp$IsHistoricalEstimated<-NULL
day.tmp$DewPoint<-NULL
day.tmp$Humidity<-NULL
tmpcons <- day.data[[i]]$Volume*day.data[[i]]$CoolingDegree
weatherCons[[i]]<-cbind(day.tmp,tmpcons)
names(weatherCons[[i]])[names(weatherCons[[i]])=='tmpcons']<-"Consumption"
weatherCons[[i]]$Obs <- NULL
}
# Adding vacation periods as attributes in day.data. Dates are taken from
# http://skoleferie-dk.dk/skoleferie-aalborg/?fbclid=IwAR1l2J2t9mHz8JC3qho9stqOj7k7e8MrJQ461a7Iy6_Ekf5AaL8HNzZY9WM
WinterBreakDates <- as.POSIXlt(seq(as.Date('2018-02-10'),as.Date('2018-02-18'), by="days"),format = "%Y-%m-%d", tz = "GMT")
SpringBreakDates <- as.POSIXlt(seq(as.Date('2018-03-24'),as.Date('2018-04-02'), by="days"),format = "%Y-%m-%d", tz = "GMT")
AutumnBreakDates <- as.POSIXlt(seq(as.Date('2018-10-13'),as.Date('2018-10-21'), by="days"),format = "%Y-%m-%d", tz = "GMT")
ChristmasBreakDates <- as.POSIXlt(seq(as.Date('2018-12-22'),as.Date('2019-01-02'), by="days"),format = "%Y-%m-%d", tz = "GMT")
for (i in 1:n)
{
tmp_WinterBreak <-as.integer(apply(day.data[[i]],1,function(x) x %in% WinterBreakDates)[1,])
tmp_SpringBreak <-as.integer(apply(day.data[[i]],1,function(x) x %in% SpringBreakDates)[1,])
tmp_AutumnBreak <-as.integer(apply(day.data[[i]],1,function(x) x %in% AutumnBreakDates)[1,])
tmp_ChristmasBreak <-as.integer(apply(day.data[[i]],1,function(x) x %in% ChristmasBreakDates)[1,])
day.data[[i]]$WinterBreak<-tmp_WinterBreak
weatherCons[[i]]$WinterBreak<-tmp_WinterBreak
day.data[[i]]$SpringBreak<-tmp_SpringBreak
weatherCons[[i]]$SpringBreak<-tmp_SpringBreak
day.data[[i]]$AutumnBreak<-tmp_AutumnBreak
weatherCons[[i]]$AutumnBreak<-tmp_AutumnBreak
day.data[[i]]$ChristmasBreak<-tmp_ChristmasBreak
weatherCons[[i]]$ChristmasBreak<-tmp_ChristmasBreak
weatherCons[[i]]$Weekend<-day.data[[i]]$Weekend
}
tmp_WinterBreak <-as.integer(apply(day.avg,1,function(x) x %in% WinterBreakDates)[1,])
tmp_SpringBreak <-as.integer(apply(day.avg,1,function(x) x %in% SpringBreakDates)[1,])
tmp_AutumnBreak <-as.integer(apply(day.avg,1,function(x) x %in% AutumnBreakDates)[1,])
tmp_ChristmasBreak <-as.integer(apply(day.avg,1,function(x) x %in% ChristmasBreakDates)[1,])
day.avg$Holiday <- as.factor(1*tmp_WinterBreak+2*tmp_SpringBreak+3*tmp_AutumnBreak+4*tmp_ChristmasBreak)
levels(day.avg$Holiday) <- c('Working days', 'Winter break', 'Spring break', 'Autumn break', 'Christmas break')
rm(i,file.names,data.path,dt.tmp,sStartDays,sEndDays,tmp,x,tmp.df,tmp.xts,t1,d1,weatherEnd,weatherStart,tmp.wd,tmp.dat,tmp.d1,tmp.d2,par,day.tmp,tmp.data,tmp.index,weightavg,m,j,k,dt.tmp.noNA,BBR.tmp)
rm(AutumnBreakDates,ChristmasBreakDates,tmp.coord,tmp.polar,tmp.rekt,SpringBreakDates,WinterBreakDates,jan1,sat,sun,tmp_AutumnBreak,tmp_ChristmasBreak,tmp_SpringBreak,tmp_WinterBreak,tmpcons,Weekend)
weather$Condition
